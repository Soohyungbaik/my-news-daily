import requests
from bs4 import BeautifulSoup
from datetime import datetime
import os
import smtplib
from email.mime.text import MIMEText

# ë‚ ì§œ ì§€ì •
today = datetime.today().strftime('%Y-%m-%d')
source_url = f"https://soohyungbaik.github.io/my-news-daily/dailynews/{today}.html"

HEADERS = {
    "User-Agent": "Mozilla/5.0"
}

# HTML ë¡œë“œ (ì›ê²© ìš°ì„ , ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ëŒ€ì²´)
try:
    res = requests.get(source_url, headers=HEADERS)
    res.raise_for_status()
    res.encoding = res.apparent_encoding
    html_text = res.text
    print(f"âœ… ì›ê²© ë‰´ìŠ¤ íŒŒì¼ ìš”ì²­ ì„±ê³µ: {source_url}")
except Exception:
    local_path = f"dailynews/{today}.html"
    if os.path.exists(local_path):
        print(f"âš ï¸ ì›ê²© ìš”ì²­ ì‹¤íŒ¨, ë¡œì»¬ íŒŒì¼ë¡œ ëŒ€ì²´: {local_path}")
        with open(local_path, 'r', encoding='utf-8') as f:
            html_text = f.read()
    else:
        print("âŒ ì›ê²© ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨ ë° ë¡œì»¬ íŒŒì¼ë„ ì—†ìŒ")
        html_text = None

# í‚¤ì›Œë“œ ë° ë§¤ì²´ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
keywords, media_list = [], []
if os.path.exists('keywords.txt'):
    with open('keywords.txt', 'r', encoding='utf-8') as f:
        keywords = [line.strip().lower() for line in f if line.strip()]
if os.path.exists('media_list.txt'):
    with open('media_list.txt', 'r', encoding='utf-8') as f:
        media_list = [line.strip().lower() for line in f if line.strip()]

# HTML í…œí”Œë¦¿ ì‹œì‘
html = f"""<html><head><meta charset='UTF-8'>
<style>
  body {{ font-family: sans-serif; }}
  .item {{ margin-bottom: 10px; }}
</style></head>
<body>
<h2>[ë‰´ìŠ¤ë ˆí„°] {today}</h2>
<ul>
"""

filtered = []
matching_urls = []

def extract_og_title(url):
    try:
        res = requests.get(url, headers=HEADERS, timeout=5)
        if res.status_code == 200:
            res.encoding = res.apparent_encoding
            soup = BeautifulSoup(res.text, 'html.parser')
            og = soup.find("meta", property="og:title")
            if og and og.get("content"):
                return og["content"].strip()
    except Exception as e:
        print(f"âš ï¸ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {url} - {e}")
    return None

if html_text:
    soup = BeautifulSoup(html_text, 'html.parser')
    items = soup.select('li > a')

    for item in items:
        raw_title = item.text.strip()
        url = item['href'].strip()
        lower_url = url.lower()

        # URLë¡œ ë³¸ë¬¸ ì ‘ê·¼ ë° í‚¤ì›Œë“œ í•„í„°ë§
        try:
            article_res = requests.get(url, headers=HEADERS, timeout=5)
            article_res.encoding = article_res.apparent_encoding
            article_text = article_res.text.lower() if article_res.status_code == 200 else ''
        except:
            article_text = ''

        og_title = extract_og_title(url)
        effective_title = og_title if og_title else raw_title
        lower_title = effective_title.lower()

        keyword_match = any(k in lower_title or k in article_text for k in keywords)
        media_match = any(m in lower_url for m in media_list)

        if keyword_match or media_match:
            filtered.append((effective_title, url))
            matching_urls.append(url)

    if filtered:
        for title, url in filtered:
            html += f"<li class='item'><a href='{url}'>{title}</a></li>"
    else:
        html += "<li class='item'><i>ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.</i></li>"
        if matching_urls:
            html += "<li><strong>ğŸ“Œ ë§¤ì¹­ëœ URL ëª©ë¡:</strong></li>"
            for u in matching_urls:
                html += f"<li><a href='{u}'>{u}</a></li>"
        elif keywords:
            html += "<li><strong>ğŸ“Œ ì˜¤ëŠ˜ì˜ í‚¤ì›Œë“œ ëª©ë¡:</strong></li>"
            for kw in keywords:
                html += f"<li>- {kw}</li>"
else:
    html += "<li class='item'><i>ê¸ˆì¼ ë‰´ìŠ¤ ì†ŒìŠ¤ê°€ ì—†ì–´ í‚¤ì›Œë“œë§Œ ì œê³µí•©ë‹ˆë‹¤.</i></li>"
    for kw in keywords:
        html += f"<li>- {kw}</li>"

html += "</ul></body></html>"

# ì €ì¥
output_dir = "daily_html"
os.makedirs(output_dir, exist_ok=True)
output_path = f"{output_dir}/{today}.html"
with open(output_path, 'w', encoding='utf-8') as f:
    f.write(html)
print(f"âœ… ë‰´ìŠ¤ HTML ìƒì„± ì™„ë£Œ: {output_path}")

# index.html ê°±ì‹ 
index_path = "index.html"
if not os.path.exists(index_path):
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("<html><head><meta charset='UTF-8'><title>ë‰´ìŠ¤ ëª¨ìŒ</title></head><body><h1>ë‰´ìŠ¤ ëª¨ìŒ</h1><ul>\n<!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->\n</ul></body></html>")

with open(index_path, 'r', encoding='utf-8') as f:
    index_html = f.read()

new_entry = f"<li><a href=\"{output_dir}/{today}.html\">{today}</a></li>"
if new_entry not in index_html:
    index_html = index_html.replace("<!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->", f"{new_entry}\n<!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->")
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_html)

# ì´ë©”ì¼ ì „ì†¡
msg = MIMEText(html, 'html')
msg['Subject'] = f"[ë‰´ìŠ¤ë ˆí„°] {today}"
msg['From'] = os.getenv("EMAIL_FROM")
msg['To'] = os.getenv("EMAIL_TO")

try:
    server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
    server.login(os.getenv("EMAIL_FROM"), os.getenv("EMAIL_PASSWORD"))
    server.send_message(msg)
    server.quit()
    print("âœ… ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ")
except Exception as e:
    print("âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨:", e)

