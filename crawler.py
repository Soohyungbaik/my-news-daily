import requests
from bs4 import BeautifulSoup
from datetime import datetime
import os
import smtplib
from email.mime.text import MIMEText
import shutil

# ì˜¤ëŠ˜ ë‚ ì§œ
today = datetime.today().strftime('%Y-%m-%d')

# ë‰´ìŠ¤ ì†ŒìŠ¤ URL
source_url = f"https://baik1204.github.io/SC-daily-news/{today}.html"
res = requests.get(source_url)

# í‚¤ì›Œë“œ ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists('keywords.txt'):
    with open('keywords.txt', 'r', encoding='utf-8') as f:
        keywords = [line.strip() for line in f if line.strip()]
else:
    keywords = []

# ë§¤ì²´ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists('media_list.txt'):
    with open('media_list.txt', 'r', encoding='utf-8') as f:
        media_list = [line.strip() for line in f if line.strip()]
else:
    media_list = []

# ë³¸ë¬¸ ë‚´ í‚¤ì›Œë“œ ê²€ì‚¬ í•¨ìˆ˜
def check_keyword_in_article(url, keywords):
    try:
        res = requests.get(url, timeout=5)
        if res.status_code != 200:
            return False
        soup = BeautifulSoup(res.text, 'html.parser')
        text = soup.get_text()
        return any(k.lower() in text.lower() for k in keywords)
    except Exception as e:
        print(f"âŒ ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {url} - {e}")
        return False

# HTML í…œí”Œë¦¿ ì‹œì‘
html = f"""
<html><head><meta charset='UTF-8'>
<style>
  body {{ font-family: sans-serif; }}
  .item {{ margin-bottom: 10px; }}
</style></head>
<body>
<h2>[ë‰´ìŠ¤ë ˆí„°] {today}</h2>
<ul>
"""

filtered = []

if res.status_code == 200:
    soup = BeautifulSoup(res.text, 'html.parser')
    items = soup.select('li > a')

    for item in items:
        title = item.text
        url = item['href']
        keyword_match = any(k.lower() in title.lower() for k in keywords) if keywords else False
        media_match = any(m.lower() in title.lower() or m.lower() in url.lower() for m in media_list) if media_list else False
        body_match = check_keyword_in_article(url, keywords) if keywords else False

        print(f"ğŸ” {title}")
        print(f"    ì œëª© ë§¤ì¹˜: {keyword_match}, ë§¤ì²´ ë§¤ì¹˜: {media_match}, ë³¸ë¬¸ ë§¤ì¹˜: {body_match}")

        if (not keywords and not media_list) or keyword_match or media_match or body_match:
            filtered.append((title, url))

    if filtered:
        for title, url in filtered:
            html += f"<li class='item'><a href='{url}'>{title}</a></li>"
    else:
        html += "<li class='item'><i>ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.</i></li>"
else:
    html += "<li class='item'><i>ê¸ˆì¼ ë‰´ìŠ¤ ì†ŒìŠ¤ê°€ ì—†ì–´ í‚¤ì›Œë“œë§Œ ì œê³µë©ë‹ˆë‹¤.</i></li>"

html += "</ul></body></html>"

# daily_html ë””ë ‰í† ë¦¬ ì²˜ë¦¬
output_dir = "daily_html"
if os.path.exists(output_dir):
    if not os.path.isdir(output_dir):
        print(f"âš ï¸ '{output_dir}'ëŠ” íŒŒì¼ì…ë‹ˆë‹¤. ì‚­ì œ í›„ ë””ë ‰í† ë¦¬ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        os.remove(output_dir)
        os.makedirs(output_dir)
    else:
        os.makedirs(output_dir, exist_ok=True)
else:
    os.makedirs(output_dir)

# ë‰´ìŠ¤ HTML ì €ì¥
output_path = f"{output_dir}/{today}.html"
with open(output_path, 'w', encoding='utf-8') as f:
    f.write(html)

# index.html ê°±ì‹ 
index_path = "index.html"

if os.path.exists(index_path):
    if not os.path.isfile(index_path):
        print(f"âš ï¸ '{index_path}'ëŠ” íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ì‚­ì œ í›„ ìƒì„±í•©ë‹ˆë‹¤.")
        shutil.rmtree(index_path)
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write("""<html>
  <head>
    <meta charset="UTF-8">
    <title>ë‰´ìŠ¤ ëª¨ìŒ</title>
  </head>
  <body>
    <h1>ë‰´ìŠ¤ ëª¨ìŒ</h1>
    <ul>
      <!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->
    </ul>
  </body>
</html>""")
    else:
        with open(index_path, 'r', encoding='utf-8') as f:
            content = f.read()
        if "<ul>" not in content:
            with open(index_path, 'w', encoding='utf-8') as f:
                f.write("""<html>
  <head>
    <meta charset="UTF-8">
    <title>ë‰´ìŠ¤ ëª¨ìŒ</title>
  </head>
  <body>
    <h1>ë‰´ìŠ¤ ëª¨ìŒ</h1>
    <ul>
      <!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->
    </ul>
  </body>
</html>""")
else:
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("""<html>
  <head>
    <meta charset="UTF-8">
    <title>ë‰´ìŠ¤ ëª¨ìŒ</title>
  </head>
  <body>
    <h1>ë‰´ìŠ¤ ëª¨ìŒ</h1>
    <ul>
      <!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->
    </ul>
  </body>
</html>""")

# ë‚ ì§œ ë§í¬ ì‚½ì…
with open(index_path, 'r', encoding='utf-8') as f:
    index_html = f.read()

new_entry = f"<li><a href=\"{output_dir}/{today}.html\">{today}</a></li>"
if new_entry not in index_html:
    index_html = index_html.replace(
        "<!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->",
        f"{new_entry}\n      <!-- ë‹¤ìŒ ë‚ ì§œê°€ ìƒê¸°ë©´ crawler.pyê°€ ìë™ ì¶”ê°€ -->"
    )
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_html)

# ì´ë©”ì¼ ë°œì†¡
msg = MIMEText(html, 'html')
msg['Subject'] = f"[ë‰´ìŠ¤ë ˆí„°] {today}"
msg['From'] = os.getenv("EMAIL_FROM")
msg['To'] = os.getenv("EMAIL_TO")

try:
    server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
    server.login(os.getenv("EMAIL_FROM"), os.getenv("EMAIL_PASSWORD"))
    server.send_message(msg)
    server.quit()
    print("âœ… ì´ë©”ì¼ ì „ì†¡ ì™„ë£Œ")
except Exception as e:
    print("âŒ ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨:", e)

print(f"âœ… ë‰´ìŠ¤ HTML ìƒì„± ì™„ë£Œ: {output_path}")


