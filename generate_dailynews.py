import datetime
import os
import re
import requests
from bs4 import BeautifulSoup
from bs4 import XMLParsedAsHTMLWarning
import warnings

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=XMLParsedAsHTMLWarning)

today = datetime.date.today().strftime('%Y-%m-%d')
output_dir = "dailynews"
os.makedirs(output_dir, exist_ok=True)
output_path = os.path.join(output_dir, f"{today}.html")

# í‚¤ì›Œë“œ ë¶ˆëŸ¬ì˜¤ê¸°
keywords = []
if os.path.exists("keywords.txt"):
    with open("keywords.txt", "r", encoding="utf-8") as f:
        keywords = [line.strip().lower() for line in f if line.strip()]

# ë§¤ì²´ í•„í„°
media_list = []
if os.path.exists("media_list.txt"):
    with open("media_list.txt", "r", encoding="utf-8") as f:
        media_list = [line.strip().lower() for line in f if line.strip()]

news_items = []

# ìš”ì²­ í—¤ë”
headers = {
    "User-Agent": "Mozilla/5.0",
    "Accept-Language": "ko,en;q=0.9",
    "Referer": "https://www.google.com"
}

# ì œëª© ì¶”ì¶œ í•¨ìˆ˜
def get_article_title(url):
    try:
        with requests.Session() as s:
            res = s.get(url, headers=headers, timeout=7)
            res.encoding = res.apparent_encoding
            if res.status_code == 200:
                soup = BeautifulSoup(res.text, "html.parser")
                og_title = soup.find("meta", property="og:title")
                if og_title and og_title.get("content"):
                    return og_title["content"].strip()
                elif soup.title and soup.title.string:
                    return soup.title.string.strip()
    except Exception as e:
        print(f"âš ï¸ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {url} - {e}")
    return None

# ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def collect_news_from(sites, region, selector="a[href]"):
    print(f"ğŸŸ¡ [{region}] ìˆ˜ì§‘ ì‹œì‘")
    match_count = 0
    for url in sites:
        try:
            with requests.Session() as s:
                res = s.get(url, headers=headers, timeout=7)
                if res.status_code >= 400:
                    print(f"âš ï¸ [{region}] {url} - ì‘ë‹µ ì½”ë“œ {res.status_code} (ê³„ì† ì§„í–‰)")
                res.encoding = res.apparent_encoding
                soup = BeautifulSoup(res.text, "html.parser")
                links = soup.select(selector)
                for link in links:
                    text = link.get_text(strip=True)
                    href = link.get("href", "")
                    if not href.startswith("http"):
                        continue

                    lower_text = text.lower()
                    lower_url = href.lower()

                    keyword_match = any(k in lower_text or k in lower_url for k in keywords)
                    media_match = any(m in lower_url for m in media_list)

                    if keyword_match or media_match:
                        title = get_article_title(href)
                        if title and len(title) > 5:
                            news_items.append({"title": title, "url": href})
                            match_count += 1
                        else:
                            print(f"[{region}] ì œëª© ëˆ„ë½/ì§§ìŒ: {href}")
        except Exception as e:
            print(f"âŒ [{region}] {url} - ì˜ˆì™¸ ë°œìƒ: {e}")
    print(f"âœ… [{region}] ìˆ˜ì§‘ ì™„ë£Œ - ë§¤ì¹­ {match_count}ê±´")

# ì‚¬ì´íŠ¸ ëª©ë¡
korea_sites = [
    "https://www.inven.co.kr/webzine/news/",
    "https://www.thisisgame.com/webzine/news/nboard/263/?category=2",
    "https://www.ezyeconomy.com/news/articleList.html?sc_sub_section_code=S2N71&view_type=sm"
]

japan_sites = [
    "https://gamebiz.jp/news",
    "https://www.4gamer.net/",
    "https://www.gamer.ne.jp/",
    "https://gnn.gamer.com.tw/index.php?k=4"
]

china_sites = [
    "https://www.17173.com/",
    "https://www.youxituoluo.com/",
    "https://www.163.com/dy/media/T1439279320876.html",
    "https://news.qq.com/"
]

# ìˆ˜ì§‘ ì‹¤í–‰
collect_news_from(korea_sites, "í•œêµ­")
collect_news_from(japan_sites, "ì¼ë³¸")
collect_news_from(china_sites, "ì¤‘êµ­")

# HTML ì¶œë ¥
html = f"""<html><head><meta charset='UTF-8'>
<style>
  body {{ font-family: sans-serif; }}
  .item {{ margin-bottom: 10px; }}
</style></head>
<body>
<h2>[ë‰´ìŠ¤ë ˆí„°] {today}</h2>
<ul>
"""

if not news_items:
    html += "<li class='item'><i>ê¸ˆì¼ ë‰´ìŠ¤ ì†ŒìŠ¤ê°€ ì—†ì–´ í‚¤ì›Œë“œë§Œ ì œê³µí•©ë‹ˆë‹¤.</i></li>"
    for kw in keywords:
        html += f"<li>- {kw}</li>"
else:
    for item in news_items:
        html += f"<li class='item'><a href='{item['url']}'>{item['title']}</a></li>"

html += "</ul></body></html>"

# ì €ì¥
with open(output_path, "w", encoding="utf-8") as f:
    f.write(html)

print(f"âœ… ë‰´ìŠ¤ HTML ìƒì„± ì™„ë£Œ: {output_path}")


